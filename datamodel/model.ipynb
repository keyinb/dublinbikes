{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model for Dublin Bikes application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 18:27:02.229574: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marge the two csv with the closest date and time for convention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just need to create a collect csv files for both and put them in here\n",
    "df_bike = pd.read_csv('dynamic_4_4_23.csv')\n",
    "df_weather = pd.read_csv('weather_30_3_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike['s_time'] = df_bike['s_time'].astype(str).apply(lambda x: str(x).split(' ')[-1])\n",
    "df_weather['w_time'] = df_weather['w_time'].astype(str).apply(lambda x: str(x).split(' ')[-1])\n",
    "df_bike['datetime'] = pd.to_datetime(df_bike['s_date'].astype(str) + ' ' + df_bike['s_time'].astype(str).apply(lambda x: str(x).split(' ')[-1]))\n",
    "df_weather['datetime'] = pd.to_datetime(df_weather['w_date'].astype(str) + ' ' + df_weather['w_time'].astype(str).apply(lambda x: str(x).split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike = df_bike.sort_values('datetime')\n",
    "df_weather = df_weather.sort_values('datetime')\n",
    "\n",
    "df_main = pd.merge_asof(df_bike, df_weather, on='datetime', direction='nearest')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'name', 'bike_stands', 'available_bike_stands',\n",
       "       'available_bikes', 'status', 's_date', 's_time', 'datetime', 'latitude',\n",
       "       'longitude', 'weather_id', 'weather_main', 'weather_description',\n",
       "       'weather_icon', 'temperature', 'feels_like', 'temp_min', 'temp_max',\n",
       "       'pressure', 'humidity', 'visibility', 'wind_speed', 'wind_direction',\n",
       "       'rain_1', 'rain_3', 'snow_1', 'snow_3', 'clouds', 'sunrise', 'sunset',\n",
       "       'w_date', 'w_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['name', 'status', 's_date', 's_time','latitude',\n",
    "       'longitude', 'weather_id', 'weather_description',\n",
    "       'weather_icon', 'feels_like', 'temp_min', 'temp_max',\n",
    "       'pressure','visibility','wind_direction',\n",
    "       'rain_1', 'rain_3', 'snow_1', 'snow_3', 'clouds', 'sunrise', 'sunset',\n",
    "       'w_date', 'w_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(df_main[df_main[\"number\"] == 507].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082       0.50\n",
       "2083       0.30\n",
       "2084       0.10\n",
       "2085       0.00\n",
       "2086       0.57\n",
       "           ... \n",
       "1060225    0.02\n",
       "1060226    0.47\n",
       "1060227    0.05\n",
       "1060228    0.35\n",
       "1060229    0.92\n",
       "Name: availability_percentage, Length: 1058148, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"availability_percentage\"] = df_main[\"available_bikes\"]/(df_main[\"bike_stands\"])\n",
    "df_main[\"availability_percentage\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'bike_stands', 'available_bike_stands', 'available_bikes',\n",
       "       'datetime', 'weather_main', 'temperature', 'humidity', 'wind_speed',\n",
       "       'availability_percentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"temperature\"] = df_main[\"temperature\"] - 275.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Drizzle', 'Clouds', 'Rain', 'Clear'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"weather_main\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"datetime\"] = pd.to_datetime(df_main[\"datetime\"])\n",
    "df_main[\"year\"] = df_main[\"datetime\"].dt.year\n",
    "df_main[\"month\"] = df_main[\"datetime\"].dt.month\n",
    "df_main[\"day\"] = df_main[\"datetime\"].dt.day\n",
    "df_main[\"time\"] = df_main[\"datetime\"].dt.time\n",
    "df_main[\"hour\"] = df_main[\"datetime\"].dt.round(\"H\").dt.hour.astype(int)\n",
    "df_main[\"day_of_week\"] = df_main[\"datetime\"].dt.strftime('%A')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df_main[\"weather_main\"])\n",
    "df_main = pd.concat([df_main, one_hot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df_main[\"day_of_week\"])\n",
    "df_main = pd.concat([df_main, one_hot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['datetime', 'weather_main', 'year',\n",
    "       'month', 'day', 'time', 'day_of_week', 'available_bike_stands',\n",
    "       'available_bikes'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_main.columns:\n",
    "    if df_main[column].dtype == \"uint8\":\n",
    "        df_main[column] = df_main[column].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number                       int64\n",
       "bike_stands                  int64\n",
       "available_bike_stands        int64\n",
       "available_bikes              int64\n",
       "temperature                float64\n",
       "humidity                     int64\n",
       "wind_speed                 float64\n",
       "availability_percentage    float64\n",
       "Clear                        int64\n",
       "Clouds                       int64\n",
       "Drizzle                      int64\n",
       "Rain                         int64\n",
       "hour                         int64\n",
       "Friday                       int64\n",
       "Monday                       int64\n",
       "Saturday                     int64\n",
       "Sunday                       int64\n",
       "Thursday                     int64\n",
       "Tuesday                      int64\n",
       "Wednesday                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data into training/validation and testing\n",
    "- Drop all data for the 3rd March\n",
    "- Train- first 3 weeks, Validation next 1 week. Test 1 week\n",
    "- Starting at Saturday 00:00AM\n",
    "- Dates Training 4/3/23 to end of 24/3/23\n",
    "- Dates validation 25/3/23 to end of 31st\n",
    "- Dates training 1/4/23 to end of 7/4th/23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def divide_data(station_number, dataframe):\n",
    "    df_main = dataframe[dataframe[\"number\"] == station_number].copy()\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train, test = train_test_split(df_main, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Split the train and test sets into x and y\n",
    "    x_train = train.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_train = train[\"availability_percentage\"]\n",
    "    x_test = test.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_test = test[\"availability_percentage\"]\n",
    "\n",
    "    return df_main, x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the relation between x columns and y column\n",
    "\n",
    "if you find some unrelated input columns from the scatter below, you can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_xy(x, y):\n",
    "    for column in x.columns:\n",
    "        plt.scatter(x[column], y)\n",
    "        plt.title(column)\n",
    "        plt.ylabel(\"Availability\")\n",
    "        plt.xlabel(column)\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(train_x, train_y, test_x, test_y):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(train_x, train_y)\n",
    "    print(f\"train score : {reg.score(train_x, train_y)}\")\n",
    "    print(f\"test score : {reg.score(test_x, test_y)}\")\n",
    "    return reg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model into a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def save_model(model, stationnumber):\n",
    "    filename = f'/Users/ikeoshuya/Documents/GitHub/dublinbikes/datamodel/models/model_{stationnumber}.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the models with for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for station_number in df_main[\"number\"].unique():\n",
    "    df_station, x_train, y_train, x_test, y_test = divide_data(station_number, df)\n",
    "    model = training_model(x_train, y_train, x_test, y_test)\n",
    "    save_model(model, station_number)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp30830_t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model for Dublin Bikes application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression ## maybe logisitic regression??????"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marge the two csv with the closest date and time for convention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just need to create a collect csv files for both and put them in here\n",
    "df_bike = pd.read_csv('dynamic_4_4_23 copy.csv')\n",
    "df_weather = pd.read_csv('weather_4_4_23 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike['s_time'] = df_bike['s_time'].astype(str).apply(lambda x: str(x).split(' ')[-1])\n",
    "df_weather['w_time'] = df_weather['w_time'].astype(str).apply(lambda x: str(x).split(' ')[-1])\n",
    "df_bike['datetime'] = pd.to_datetime(df_bike['s_date'].astype(str) + ' ' + df_bike['s_time'].astype(str).apply(lambda x: str(x).split(' ')[-1]))\n",
    "df_weather['datetime'] = pd.to_datetime(df_weather['w_date'].astype(str) + ' ' + df_weather['w_time'].astype(str).apply(lambda x: str(x).split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike = df_bike.sort_values('datetime')\n",
    "df_weather = df_weather.sort_values('datetime')\n",
    "\n",
    "df_main = pd.merge_asof(df_bike, df_weather, on='datetime', direction='nearest')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'name', 'bike_stands', 'available_bike_stands',\n",
       "       'available_bikes', 'status', 's_date', 's_time', 'datetime', 'latitude',\n",
       "       'longitude', 'weather_id', 'weather_main', 'weather_description',\n",
       "       'weather_icon', 'temperature', 'feels_like', 'pressure', 'humidity',\n",
       "       'visibility', 'wind_speed', 'wind_direction', 'rain', 'snow', 'clouds',\n",
       "       'sunrise', 'sunset', 'w_date', 'w_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['name','status', 's_date', 's_time','latitude',\n",
    "       'longitude', 'weather_id', 'weather_description',\n",
    "       'weather_icon', 'feels_like',\n",
    "       'pressure','visibility','wind_direction',\n",
    "       'rain','snow', 'sunrise', 'sunset',\n",
    "       'w_date', 'w_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(df_main[df_main[\"number\"] == 507].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-03-03T10:43:51.000000000', '2023-03-03T10:44:01.000000000',\n",
       "       '2023-03-03T10:44:04.000000000', ...,\n",
       "       '2023-04-04T08:45:33.000000000', '2023-04-04T08:45:40.000000000',\n",
       "       '2023-04-04T08:45:47.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"datetime\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_main = df_main.drop(df_main[\"datatime] < ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main[(df_main['datetime'] >= '2023-03-04') & (df_main['datetime'] <= '2023-04-03')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-03-04T00:00:01.000000000', '2023-03-04T00:00:15.000000000',\n",
       "       '2023-03-04T00:00:22.000000000', ...,\n",
       "       '2023-04-02T23:59:21.000000000', '2023-04-02T23:59:38.000000000',\n",
       "       '2023-04-02T23:59:55.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"datetime\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20127      0.20\n",
       "20128      0.20\n",
       "20129      1.00\n",
       "20130      1.00\n",
       "20131      0.25\n",
       "           ... \n",
       "1001188    0.21\n",
       "1001189    0.21\n",
       "1001190    0.21\n",
       "1001191    0.43\n",
       "1001192    0.43\n",
       "Name: availability_percentage, Length: 981066, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"availability_percentage\"] = df_main[\"available_bikes\"]/(df_main[\"bike_stands\"])\n",
    "df_main[\"availability_percentage\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'bike_stands', 'available_bike_stands', 'available_bikes',\n",
       "       'datetime', 'weather_main', 'temperature', 'humidity', 'wind_speed',\n",
       "       'clouds', 'availability_percentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"temperature\"] = df_main[\"temperature\"] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clouds', 'Drizzle', 'Rain', 'Clear', 'Snow', 'Mist', 'Fog'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"weather_main\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"datetime\"] = pd.to_datetime(df_main[\"datetime\"])\n",
    "df_main[\"year\"] = df_main[\"datetime\"].dt.year\n",
    "df_main[\"month\"] = df_main[\"datetime\"].dt.month\n",
    "df_main[\"day\"] = df_main[\"datetime\"].dt.day\n",
    "df_main[\"time\"] = df_main[\"datetime\"].dt.time\n",
    "df_main[\"hour\"] = df_main[\"datetime\"].dt.round(\"H\").dt.hour.astype(int)\n",
    "df_main[\"day_of_week\"] = df_main[\"datetime\"].dt.strftime('%A')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df_main[\"weather_main\"])\n",
    "df_main = pd.concat([df_main, one_hot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df_main[\"day_of_week\"])\n",
    "df_main = pd.concat([df_main, one_hot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['datetime', 'bike_stands','weather_main', 'year',\n",
    "       'month', 'day', 'time', 'day_of_week', 'available_bike_stands',\n",
    "       'available_bikes'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_main.columns:\n",
    "    if df_main[column].dtype == \"uint8\":\n",
    "        df_main[column] = df_main[column].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number                       int64\n",
       "temperature                float64\n",
       "humidity                     int64\n",
       "wind_speed                 float64\n",
       "clouds                       int64\n",
       "availability_percentage    float64\n",
       "hour                         int64\n",
       "Clear                        int64\n",
       "Clouds                       int64\n",
       "Drizzle                      int64\n",
       "Fog                          int64\n",
       "Mist                         int64\n",
       "Rain                         int64\n",
       "Snow                         int64\n",
       "Friday                       int64\n",
       "Monday                       int64\n",
       "Saturday                     int64\n",
       "Sunday                       int64\n",
       "Thursday                     int64\n",
       "Tuesday                      int64\n",
       "Wednesday                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number                     0\n",
      "temperature                0\n",
      "humidity                   0\n",
      "wind_speed                 0\n",
      "clouds                     0\n",
      "availability_percentage    0\n",
      "hour                       0\n",
      "Clear                      0\n",
      "Clouds                     0\n",
      "Drizzle                    0\n",
      "Fog                        0\n",
      "Mist                       0\n",
      "Rain                       0\n",
      "Snow                       0\n",
      "Friday                     0\n",
      "Monday                     0\n",
      "Saturday                   0\n",
      "Sunday                     0\n",
      "Thursday                   0\n",
      "Tuesday                    0\n",
      "Wednesday                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_main.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data into training/validation and testing\n",
    "- Drop all data for the 3rd March\n",
    "- Train- first 3 weeks, Validation next 1 week. Test 1 week\n",
    "- Starting at Saturday 00:00AM\n",
    "- Dates Training 4/3/23 to end of 24/3/23\n",
    "- Dates validation 25/3/23 to end of 31st\n",
    "- Dates training 1/4/23 to end of 7/4th/23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def divide_data(station_number, dataframe):\n",
    "    df_main = dataframe[dataframe[\"number\"] == station_number].copy()\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train, test = train_test_split(df_main, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Split the train and test sets into x and y\n",
    "    x_train = train.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_train = train[\"availability_percentage\"]\n",
    "    x_test = test.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_test = test[\"availability_percentage\"]\n",
    "\n",
    "    return df_main, x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def divide_data_intothree(station_number, dataframe):\n",
    "    df_main = dataframe[dataframe[\"number\"] == station_number].copy()\n",
    "\n",
    "    # Split the data into train and test sets (80% train, 20% test)\n",
    "    train, test = train_test_split(df_main, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Split the train set into train and validation sets (60% train, 20% validation)\n",
    "    train, validation = train_test_split(train, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Split the train, validation, and test sets into x and y\n",
    "    x_train = train.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_train = train[\"availability_percentage\"]\n",
    "    x_validation = validation.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_validation = validation[\"availability_percentage\"]\n",
    "    x_test = test.drop([\"availability_percentage\", \"number\"], axis=1)\n",
    "    y_test = test[\"availability_percentage\"]\n",
    "\n",
    "    return df_main, x_train, y_train, x_validation, y_validation, x_test, y_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the relation between x columns and y column\n",
    "\n",
    "if you find some unrelated input columns from the scatter below, you can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_xy(x, y):\n",
    "    for column in x.columns:\n",
    "        plt.scatter(x[column], y)\n",
    "        plt.title(column)\n",
    "        plt.ylabel(\"Availability\")\n",
    "        plt.xlabel(column)\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(train_x, train_y, test_x, test_y):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(train_x, train_y)\n",
    "    print(f\"train score : {reg.score(train_x, train_y):.4f}\")\n",
    "    print(f\"test score : {reg.score(test_x, test_y):.4f}\")\n",
    "    return reg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model into a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def save_model(model, stationnumber):\n",
    "    filename = f'/Users/ikeoshuya/Documents/GitHub/dublinbikes/datamodel/model_RFR/model_{stationnumber}.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the models with for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for station_number in df_main[\"number\"].unique():\\n    df_station, x_train, y_train, x_test, y_test = divide_data(station_number, df_main)\\n    model = training_model(x_train, y_train, x_test, y_test)\\n    #save_model(model, station_number)'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for station_number in df_main[\"number\"].unique():\n",
    "    df_station, x_train, y_train, x_test, y_test = divide_data(station_number, df_main)\n",
    "    model = training_model(x_train, y_train, x_test, y_test)\n",
    "    #save_model(model, station_number)\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_model_randomForest(train_x, train_y, test_x, test_y):\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(train_x, train_y)\n",
    "    train_r2 = rfr.score(train_x, train_y)\n",
    "    test_r2 = rfr.score(test_x, test_y)\n",
    "    y_pred = rfr.predict(test_x)\n",
    "    mae = mean_absolute_error(test_y, y_pred)\n",
    "    print(f\"Train R-squared: {train_r2:.4f}\")\n",
    "    print(f\"Test R-squared: {test_r2:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    return rfr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for station_number in df_main[\"number\"].unique():\\n    df_station, x_train, y_train, x_test, y_test = divide_data(station_number, df_main)\\n    model = training_model_randomForest(x_train, y_train, x_test, y_test)\\n    save_model(model, station_number)'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for station_number in df_main[\"number\"].unique():\n",
    "    df_station, x_train, y_train, x_test, y_test = divide_data(station_number, df_main)\n",
    "    model = training_model_randomForest(x_train, y_train, x_test, y_test)\n",
    "    save_model(model, station_number)\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what columns are impportant to make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temperature</td>\n",
       "      <td>1.729427e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>1.726033e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humidity</td>\n",
       "      <td>1.628933e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hour</td>\n",
       "      <td>1.614562e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>1.009734e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Monday</td>\n",
       "      <td>7.470717e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clouds</td>\n",
       "      <td>4.039320e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clouds</td>\n",
       "      <td>2.202971e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>2.185722e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>2.009092e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1.715898e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Friday</td>\n",
       "      <td>1.363754e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rain</td>\n",
       "      <td>1.052488e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5.252644e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Snow</td>\n",
       "      <td>1.486835e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drizzle</td>\n",
       "      <td>1.179356e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clear</td>\n",
       "      <td>6.274905e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mist</td>\n",
       "      <td>1.851776e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fog</td>\n",
       "      <td>1.714470e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        columns   importances\n",
       "0   temperature  1.729427e-01\n",
       "2    wind_speed  1.726033e-01\n",
       "1      humidity  1.628933e-01\n",
       "4          hour  1.614562e-01\n",
       "15       Sunday  1.009734e-01\n",
       "13       Monday  7.470717e-02\n",
       "3        clouds  4.039320e-02\n",
       "6        Clouds  2.202971e-02\n",
       "14     Saturday  2.185722e-02\n",
       "16     Thursday  2.009092e-02\n",
       "17      Tuesday  1.715898e-02\n",
       "12       Friday  1.363754e-02\n",
       "10         Rain  1.052488e-02\n",
       "18    Wednesday  5.252644e-03\n",
       "11         Snow  1.486835e-03\n",
       "7       Drizzle  1.179356e-03\n",
       "5         Clear  6.274905e-04\n",
       "9          Mist  1.851776e-04\n",
       "8           Fog  1.714470e-18"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"columns\" : x_train.columns, \"importances\": model.feature_importances_}).sort_values(\"importances\", ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to change the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def tuning_randomForest(train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],              \n",
    "        'max_depth': [None, 10, 20],                  \n",
    "        'min_samples_split': [2, 5, 10],               \n",
    "        'min_samples_leaf': [1, 2, 4],                 \n",
    "        'max_features': ['sqrt', 'log2', 5, 10, None]  \n",
    "    }\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "\n",
    "    grid_search = GridSearchCV(rfr, param_grid, cv=5)\n",
    "    grid_search.fit(train_x, train_y)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "    rfr_best = RandomForestRegressor(**best_params)\n",
    "    rfr_best.fit(train_x, train_y)\n",
    "\n",
    "    train_r2 = rfr_best.score(train_x, train_y)  \n",
    "    val_r2 = rfr_best.score(val_x, val_y)     \n",
    "    mae = mean_absolute_error(test_y, rfr_best.predict(test_x)) \n",
    "    print(f\"Train R-squared: {train_r2:.4f}\")\n",
    "    print(f\"Validation R-squared: {val_r2:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\") \n",
    "\n",
    "    return rfr_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train R-squared: 0.9853\n",
      "Validation R-squared: 0.9788\n",
      "Mean Absolute Error: 0.0158\n"
     ]
    }
   ],
   "source": [
    "for station_number in df_main[\"number\"].unique():\n",
    "    df_station, x_train, y_train, x_val, y_val, x_test, y_test = divide_data_intothree(station_number, df_main)\n",
    "    model = tuning_randomForest(x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    save_model(model, station_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp30830_t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
